{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9c60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c29e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936ab35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class tp represent a website that we have scraped\n",
    "    \"\"\"\n",
    "    url:str\n",
    "    title:str\n",
    "    text:str\n",
    "\n",
    "    def __init__(self,url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"   \n",
    "        self.url=url\n",
    "        response=requests.get(url) \n",
    "        soup=BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "        self.title=soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429662fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "ed=Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db5cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a59c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt=f\"you are looking for website titled {website.title}\"\n",
    "    user_prompt+=\"the content of this website is as follows: \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"   \n",
    "    user_prompt+=website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e89709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84d8b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website=Website(url)\n",
    "    messages=messages_for(Website)\n",
    "    response=ollama.chat(model=model,messages=messages)\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd767383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Edward Donner Website Summary\n",
      "=====================================\n",
      "\n",
      "This website is the personal blog of Ed Donner, a tech enthusiast and AI expert. The site showcases his experiences as the co-founder and CTO of Nebula.io, an AI startup applying machine learning to help people discover their potential.\n",
      "\n",
      "## News/Announcements\n",
      "------------------------\n",
      "\n",
      "* [May 28, 2025]: Ed Donner announces plans to release courses on LLM expertise and leadership.\n",
      "* [May 18, 2025]: A briefing on the latest developments in AI is scheduled for 2025.\n",
      "* [April 21, 2025]: The Complete Agentic AI Engineering Course is released.\n",
      "* [January 23, 2025]: An LLM Workshop - Hands-on with Agents - is announced.\n",
      "\n",
      "## Features\n",
      "------------\n",
      "\n",
      "* **LLM Arena**: A space where large language models (LLMs) compete in a battle of diplomacy and cunning.\n",
      "* **Connect Four**: A game that showcases Ed Donner's AI expertise.\n",
      "* **Outsmart**: A section that features articles on staying ahead of the curve in AI and technology.\n",
      "\n",
      "## Contact\n",
      "---------\n",
      "\n",
      "Ed Donner can be reached at ed [at] edwarddonner [dot] com or through his website.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ollama\n",
    "\n",
    "# Define a Website class\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title\"\n",
    "        self.text = soup.get_text()\n",
    "\n",
    "# Build user prompt\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled '{website.title}'.\\n\"\n",
    "    user_prompt += \"The content of this website is as follows:\\n\\n\"\n",
    "    user_prompt += \"Please provide a short summary of this website in markdown. \"\n",
    "    user_prompt += \"If it includes news or announcements, summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "# Build messages\n",
    "def messages_for(website):\n",
    "    system_prompt = \"You are a helpful summarization assistant.\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "# Main summarize function\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    messages = messages_for(website)\n",
    "    model = \"llama3.2\"\n",
    "    response = ollama.chat(model=model, messages=messages)\n",
    "    return response['message']['content']\n",
    "\n",
    "# Example usage\n",
    "summary_text = summarize(\"https://edwarddonner.com\")\n",
    "print(summary_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
